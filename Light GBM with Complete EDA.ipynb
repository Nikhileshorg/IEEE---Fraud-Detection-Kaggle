{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "warnings.simplefilter('ignore')\n",
    "files = ['E:\\\\Projects folder\\\\ieee-fraud-detection\\\\train_transaction.csv', \n",
    "         'E:\\\\Projects folder\\\\ieee-fraud-detection\\\\test_transaction.csv',\n",
    "         'E:\\\\Projects folder\\\\ieee-fraud-detection\\\\train_identity.csv',\n",
    "         'E:\\\\Projects folder\\\\ieee-fraud-detection\\\\test_identity.csv',\n",
    "         'E:\\\\Projects folder\\\\ieee-fraud-detection\\\\sample_submission.csv']\n",
    "def load_data(file):\n",
    "    return reduce_mem_usage(pd.read_csv(file))\n",
    "\n",
    "with multiprocessing.Pool() as pool:\n",
    "    test_identity, test_transaction, train_identity, train_transaction, sample_submission = pool.map(load_data, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction['TransactionAmt'] = train_transaction['TransactionAmt'].astype(float)\n",
    "total = len(train_transaction)\n",
    "total_amt = train_transaction.groupby(['isFraud'])['TransactionAmt'].sum().sum()\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_tr = sns.countplot(x='isFraud', data=train_transaction)\n",
    "plot_tr.set_title(\"Fraud Transactions Distribution \\n 0: No Fraud | 1: Fraud\", fontsize=18)\n",
    "plot_tr.set_xlabel(\"Is fraud?\", fontsize=16)\n",
    "plot_tr.set_ylabel('Count', fontsize=16)\n",
    "for p in plot_tr.patches:\n",
    "    height = p.get_height()\n",
    "    plot_tr.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\", fontsize=15) \n",
    "    \n",
    "percent_amt = (train_transaction.groupby(['isFraud'])['TransactionAmt'].sum())\n",
    "percent_amt = percent_amt.reset_index()\n",
    "plt.subplot(122)\n",
    "plot_tr_2 = sns.barplot(x='isFraud', y='TransactionAmt',  dodge=True, data=percent_amt)\n",
    "plot_tr_2.set_title(\"% Total Amount in Transaction Amt \\n 0: No Fraud | 1: Fraud\", fontsize=18)\n",
    "plot_tr_2.set_xlabel(\"Is fraud?\", fontsize=16)\n",
    "plot_tr_2.set_ylabel('Total Transaction Amount Scalar', fontsize=16)\n",
    "for p in plot_tr_2.patches:\n",
    "    height = p.get_height()\n",
    "    plot_tr_2.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total_amt * 100),\n",
    "            ha=\"center\", fontsize=15) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Ploting Transaction Amount Values Distribution</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.suptitle('Transaction Values Distribution', fontsize=22)\n",
    "plt.subplot(221)\n",
    "sub_plot_1 = sns.distplot(train_transaction[train_transaction['TransactionAmt'] <= 1000]['TransactionAmt'])\n",
    "sub_plot_1.set_title(\"Transaction Amount Distribuition <= 1000\", fontsize=18)\n",
    "sub_plot_1.set_xlabel(\"\")\n",
    "sub_plot_1.set_ylabel(\"Probability\", fontsize=15)\n",
    "\n",
    "plt.subplot(222)\n",
    "sub_plot_2 = sns.distplot(np.log(train_transaction['TransactionAmt']))\n",
    "sub_plot_2.set_title(\"Transaction Amount (Log) Distribuition\", fontsize=18)\n",
    "sub_plot_2.set_xlabel(\"\")\n",
    "sub_plot_2.set_ylabel(\"Probability\", fontsize=15)\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "sub_plot_3 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 0].shape[0]),\n",
    "                 np.sort(train_transaction[train_transaction['isFraud'] == 0]['TransactionAmt'].values), \n",
    "                 label='NoFraud', alpha=.2)\n",
    "sub_plot_3 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 1].shape[0]),\n",
    "                 np.sort(train_transaction[train_transaction['isFraud'] == 1]['TransactionAmt'].values), \n",
    "                 label='Fraud', alpha=.2)\n",
    "sub_plot_3= plt.title(\"ECDF \\nFRAUD and NO FRAUD Transaction Amount Distribution\", fontsize=18)\n",
    "sub_plot_3 = plt.xlabel(\"Index\")\n",
    "sub_plot_3 = plt.ylabel(\"Amount Distribution\", fontsize=15)\n",
    "sub_plot_3 = plt.legend()\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "plt.subplot(321)\n",
    "sub_plot_4 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 1].shape[0]), \n",
    "                 np.sort(train_transaction[train_transaction['isFraud'] == 1]['TransactionAmt'].values), \n",
    "                label='isFraud', alpha=.4)\n",
    "plt.title(\"FRAUD - Transaction Amount ECDF\", fontsize=18)\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Amount Distribution\", fontsize=12)\n",
    "\n",
    "plt.subplot(322)\n",
    "sub_plot_5 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 0].shape[0]),\n",
    "                 np.sort(train_transaction[train_transaction['isFraud'] == 0]['TransactionAmt'].values), \n",
    "                 label='NoFraud', alpha=.2)\n",
    "sub_plot_5 = plt.title(\"NO FRAUD - Transaction Amount ECDF\", fontsize=18)\n",
    "sub_plot_5 = plt.xlabel(\"Index\")\n",
    "sub_plot_5 = plt.ylabel(\"Amount Distribution\", fontsize=15)\n",
    "\n",
    "plt.suptitle('Individual ECDF Distribution', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>The Product Feature</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.crosstab(train_transaction['ProductCD'], train_transaction['isFraud'], normalize='index') * 100\n",
    "tmp = tmp.reset_index()\n",
    "tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.suptitle('ProductCD Distributions', fontsize=22)\n",
    "\n",
    "plt.subplot(221)\n",
    "plot_1 = sns.countplot(x='ProductCD', data=train_transaction)\n",
    "# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n",
    "\n",
    "plot_1.set_title(\"ProductCD Distribution\", fontsize=18)\n",
    "plot_1.set_xlabel(\"ProductCD Name\", fontsize=16)\n",
    "plot_1.set_ylabel(\"Count\", fontsize=17)\n",
    "plot_1.set_ylim(0,500000)\n",
    "for p in plot_1.patches:\n",
    "    height = p.get_height()\n",
    "    plot_1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\", fontsize=14) \n",
    "\n",
    "plt.subplot(222)\n",
    "plot_2 = sns.countplot(x='ProductCD', hue='isFraud', data=train_transaction)\n",
    "plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n",
    "plot_2_2 = plot_2.twinx()\n",
    "plot_2_2 = sns.pointplot(x='ProductCD', y='Fraud', data=tmp, color='black', order=['W', 'H',\"C\", \"S\", \"R\"], legend=False)\n",
    "plot_2_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
    "\n",
    "plot_2.set_title(\"Product CD by Target(isFraud)\", fontsize=18)\n",
    "plot_2.set_xlabel(\"ProductCD Name\", fontsize=16)\n",
    "plot_2.set_ylabel(\"Count\", fontsize=16)\n",
    "\n",
    "plt.subplot(212)\n",
    "plot_3 = sns.boxenplot(x='ProductCD', y='TransactionAmt', hue='isFraud', \n",
    "              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\n",
    "plot_3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=18)\n",
    "plot_3.set_xlabel(\"ProductCD Name\", fontsize=16)\n",
    "plot_3.set_ylabel(\"Transaction Values\", fontsize=16)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.6, top = 0.85)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Visualizing Card 1, Card 2 and Card 3 Distributions</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.loc[train_transaction.card3.isin(train_transaction.card3.value_counts()[train_transaction.card3.value_counts() < 200].index), 'card3'] = \"Others\"\n",
    "train_transaction.loc[train_transaction.card5.isin(train_transaction.card5.value_counts()[train_transaction.card5.value_counts() < 300].index), 'card5'] = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.crosstab(train_transaction['card3'], train_transaction['isFraud'], normalize='index') * 100\n",
    "tmp = tmp.reset_index()\n",
    "tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
    "\n",
    "tmp2 = pd.crosstab(train_transaction['card5'], train_transaction['isFraud'], normalize='index') * 100\n",
    "tmp2 = tmp2.reset_index()\n",
    "tmp2.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(14,22))\n",
    "\n",
    "plt.subplot(411)\n",
    "plot_1 = sns.distplot(train_transaction[train_transaction['isFraud'] == 1]['card1'], label='Fraud')\n",
    "plot_1 = sns.distplot(train_transaction[train_transaction['isFraud'] == 0]['card1'], label='NoFraud')\n",
    "plot_1.legend()\n",
    "plot_1.set_title(\"Card 1 Values Distribution by Target\", fontsize=20)\n",
    "plot_1.set_xlabel(\"Card 1 Values\", fontsize=18)\n",
    "plot_1.set_ylabel(\"Probability\", fontsize=18)\n",
    "\n",
    "plt.subplot(412)\n",
    "plot_2 = sns.distplot(train_transaction[train_transaction['isFraud'] == 1]['card2'].dropna(), label='Fraud')\n",
    "plot_2 = sns.distplot(train_transaction[train_transaction['isFraud'] == 0]['card2'].dropna(), label='NoFraud')\n",
    "plot_2.legend()\n",
    "plot_2.set_title(\"Card 2 Values Distribution by Target\", fontsize=20)\n",
    "plot_2.set_xlabel(\"Card 2 Values\", fontsize=18)\n",
    "plot_2.set_ylabel(\"Probability\", fontsize=18)\n",
    "\n",
    "plt.subplot(413)\n",
    "plot_3 = sns.countplot(x='card3', data=train_transaction, order=list(tmp.card3.values))\n",
    "plot_3_2 = plot_3.twinx()\n",
    "plot_3_2 = sns.pointplot(x='card3', y='Fraud', data=tmp, \n",
    "                    color='black', order=list(tmp.card3.values))\n",
    "plot_3_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
    "plot_3.set_title(\"Card 3 Values Distribution and % of Transaction Frauds\", fontsize=20)\n",
    "plot_3.set_xlabel(\"Card 3 Values\", fontsize=18)\n",
    "plot_3.set_ylabel(\"Count\", fontsize=18)\n",
    "for p in plot_3.patches:\n",
    "    height = p.get_height()\n",
    "    plot_3.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 25,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\") \n",
    "\n",
    "plt.subplot(414)\n",
    "plot_4 = sns.countplot(x='card5', data=train_transaction, order=list(tmp2.card5.values))\n",
    "plot_4_2 = plot_4.twinx()\n",
    "plot_4_2 = sns.pointplot(x='card5', y='Fraud', data=tmp2, \n",
    "                    color='black', order=list(tmp2.card5.values))\n",
    "plot_4_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
    "plot_4.set_title(\"Card 5 Values Distribution and % of Transaction Frauds\", fontsize=20)\n",
    "plot_4.set_xticklabels(plot_4.get_xticklabels(),rotation=90)\n",
    "plot_4.set_xlabel(\"Card 5 Values\", fontsize=18)\n",
    "plot_4.set_ylabel(\"Count\", fontsize=18)\n",
    "for p in plot_4.patches:\n",
    "    height = p.get_height()\n",
    "    plot_4.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\",fontsize=11) \n",
    "    \n",
    "plt.subplots_adjust(hspace = 0.6, top = 0.85)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Card 4 - Categorical Feature</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.crosstab(train_transaction['card4'], train_transaction['isFraud'], normalize='index') * 100\n",
    "tmp = tmp.reset_index()\n",
    "tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.suptitle('Card 4 Distributions', fontsize=22)\n",
    "\n",
    "plt.subplot(221)\n",
    "plot_1 = sns.countplot(x='card4', data=train_transaction)\n",
    "# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n",
    "plot_1.set_title(\"Card4 Distribution\", fontsize=19)\n",
    "plot_1.set_ylim(0,420000)\n",
    "plot_1.set_xlabel(\"Card4 Category Names\", fontsize=17)\n",
    "plot_1.set_ylabel(\"Count\", fontsize=17)\n",
    "for p in plot_1.patches:\n",
    "    height = p.get_height()\n",
    "    plot_1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\",fontsize=14) \n",
    "\n",
    "\n",
    "plt.subplot(222)\n",
    "plot_2 = sns.countplot(x='card4', hue='isFraud', data=train_transaction)\n",
    "plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n",
    "plot_2_2 = plot_1.twinx()\n",
    "plot_2_2 = sns.pointplot(x='card4', y='Fraud', data=tmp, \n",
    "                   color='black', legend=False, \n",
    "                   order=['discover', 'mastercard', 'visa', 'american express'])\n",
    "plot_2_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
    "plot_2.set_title(\"Card4 by Target(isFraud)\", fontsize=19)\n",
    "plot_2.set_xlabel(\"Card4 Category Names\", fontsize=17)\n",
    "plot_2.set_ylabel(\"Count\", fontsize=17)\n",
    "\n",
    "plt.subplot(212)\n",
    "plot_3 = sns.boxenplot(x='card4', y='TransactionAmt', hue='isFraud', \n",
    "              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\n",
    "plot_3.set_title(\"Card 4 Distribuition by ProductCD and Target\", fontsize=20)\n",
    "plot_3.set_xlabel(\"Card4 Category Names\", fontsize=17)\n",
    "plot_3.set_ylabel(\"Transaction Values\", fontsize=17)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.6, top = 0.85)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Card 6 - Categorical</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.crosstab(train_transaction['card6'], train_transaction['isFraud'], normalize='index') * 100\n",
    "tmp = tmp.reset_index()\n",
    "tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.suptitle('Card 6 Distributions', fontsize=22)\n",
    "\n",
    "plt.subplot(221)\n",
    "plot_1 = sns.countplot(x='card6', data=train_transaction, order=list(tmp.card6.values))\n",
    "# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n",
    "plot_1.set_title(\"Card6 Distribution\", fontsize=19)\n",
    "plot_1.set_ylim(0,480000)\n",
    "plot_1.set_xlabel(\"Card6 Category Names\", fontsize=17)\n",
    "plot_1.set_ylabel(\"Count\", fontsize=17)\n",
    "for p in plot_1.patches:\n",
    "    height = p.get_height()\n",
    "    plot_1.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\",fontsize=14) \n",
    "\n",
    "plt.subplot(222)\n",
    "plot_2 = sns.countplot(x='card6', hue='isFraud', data=train_transaction, order=list(tmp.card6.values))\n",
    "plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n",
    "plot_2_2 = plot_2.twinx()\n",
    "plot_2_2 = sns.pointplot(x='card6', y='Fraud', data=tmp, order=list(tmp.card6.values),\n",
    "                   color='black', legend=False, )\n",
    "plot_2_2.set_ylim(0,20)\n",
    "plot_2_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
    "plot_2.set_title(\"Card6 by Target(isFraud)\", fontsize=19)\n",
    "plot_2.set_xlabel(\"Card6 Category Names\", fontsize=17)\n",
    "plot_2.set_ylabel(\"Count\", fontsize=17)\n",
    "\n",
    "plt.subplot(212)\n",
    "plot_3 = sns.boxenplot(x='card6', y='TransactionAmt', hue='isFraud', order=list(tmp.card6.values),\n",
    "              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\n",
    "plot_3.set_title(\"Card 6 Distribuition by ProductCD and Target\", fontsize=20)\n",
    "plot_3.set_xlabel(\"Card6 Category Names\", fontsize=17)\n",
    "plot_3.set_ylabel(\"Transaction Values\", fontsize=17)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.6, top = 0.85)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Exploring M1-M9 Features</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n",
    "    train_transaction[columns] = train_transaction[columns].fillna(\"Miss\")\n",
    "    \n",
    "def ploting_dist_ratio(DataFile, Column, lim=2000):\n",
    "    tmp = pd.crosstab(DataFile[Column], DataFile['isFraud'], normalize='index') * 100\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.suptitle(f'{Column} Distributions ', fontsize=22)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plot_1 = sns.countplot(x=Column, data=DataFile, order=list(tmp[Column].values))\n",
    "    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n",
    "    plot_1.set_title(f\"{Column} Distribution\\nCound and %Fraud by each category\", fontsize=18)\n",
    "    plot_1.set_ylim(0,400000)\n",
    "    plot_1_2 = plot_1.twinx()\n",
    "    plot_1_2 = sns.pointplot(x=Column, y='Fraud', data=tmp, order=list(tmp[Column].values),\n",
    "                       color='black', legend=False, )\n",
    "    plot_1_2.set_ylim(0,20)\n",
    "    plot_1_2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n",
    "    plot_1.set_xlabel(f\"{Column} Category Names\", fontsize=16)\n",
    "    plot_1.set_ylabel(\"Count\", fontsize=17)\n",
    "    for p in plot_1_2.patches:\n",
    "        height = p.get_height()\n",
    "        plot_1_2.text(p.get_x()+p.get_width()/2.,\n",
    "                height + 3,\n",
    "                '{:1.2f}%'.format(height/total*100),\n",
    "                ha=\"center\",fontsize=14) \n",
    "        \n",
    "    perc_amt = (train_transaction.groupby(['isFraud',Column])['TransactionAmt'].sum() / total_amt * 100).unstack('isFraud')\n",
    "    perc_amt = perc_amt.reset_index()\n",
    "    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plot_2 = sns.boxplot(x=Column, y='TransactionAmt', hue='isFraud', \n",
    "                     data=DataFile[DataFile['TransactionAmt'] <= lim], order=list(tmp[Column].values))\n",
    "    plot_2_2 = plot_2.twinx()\n",
    "    plot_2_2 = sns.pointplot(x=Column, y='Fraud', data=perc_amt, order=list(tmp[Column].values),\n",
    "                       color='black', legend=False, )\n",
    "    plot_2_2.set_ylim(0,5)\n",
    "    plot_2_2.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n",
    "    plot_2.set_title(f\"{Column} by Transactions dist\", fontsize=18)\n",
    "    plot_2.set_xlabel(f\"{Column} Category Names\", fontsize=16)\n",
    "    plot_2.set_ylabel(\"Transaction Amount(U$)\", fontsize=16)\n",
    "        \n",
    "    plt.subplots_adjust(hspace=.4, wspace = 0.35, top = 0.80)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n",
    "    ploting_dist_ratio(train_transaction, columns, lim=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Addr1 Distributions</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.loc[train_transaction.addr1.isin(train_transaction.addr1.value_counts()[train_transaction.addr1.value_counts() <= 5000 ].index), 'addr1'] = \"Others\"\n",
    "train_transaction.loc[train_transaction.addr2.isin(train_transaction.addr2.value_counts()[train_transaction.addr2.value_counts() <= 50 ].index), 'addr2'] = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ploting_cnt_amt(DataFile, Column, lim=2000):\n",
    "    tmp = pd.crosstab(DataFile[Column], DataFile['isFraud'], normalize='index') * 100\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
    "    \n",
    "    plt.figure(figsize=(16,14))    \n",
    "    plt.suptitle(f'{Column} Distributions ', fontsize=24)\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plot_1 = sns.countplot(x=Column,data=DataFile,order=list(tmp[Column].values))\n",
    "    plot_1_2 = plot_1.twinx()\n",
    "    plot_1_2 = sns.pointplot(x=Column, y='Fraud', data=tmp, order=list(tmp[Column].values),\n",
    "                       color='black', legend=False)\n",
    "    plot_1_2.set_ylim(0,tmp['Fraud'].max()*1.1)\n",
    "    plot_1_2.set_ylabel(\"%Fraud Transactions\", fontsize=16)\n",
    "    plot_1.set_title(f\"Most Frequent {Column} values and % Fraud Transactions\", fontsize=20)\n",
    "    plot_1.set_xlabel(f\"{Column} Category Names\", fontsize=16)\n",
    "    plot_1.set_ylabel(\"Count\", fontsize=17)\n",
    "    plot_1.set_xticklabels(plot_1.get_xticklabels(),rotation=45)\n",
    "    sizes = []\n",
    "    for p in plot_1.patches:\n",
    "        height = p.get_height()\n",
    "        sizes.append(height)\n",
    "        plot_1.text(p.get_x()+p.get_width()/2.,\n",
    "                height + 3,\n",
    "                '{:1.2f}%'.format(height/total*100),\n",
    "                ha=\"center\",fontsize=12) \n",
    "        \n",
    "    plot_1.set_ylim(0,max(sizes)*1.15)\n",
    "    \n",
    "    #########################################################################\n",
    "    perc_amt = (DataFile.groupby(['isFraud',Column])['TransactionAmt'].sum() \\\n",
    "                / DataFile.groupby([Column])['TransactionAmt'].sum() * 100).unstack('isFraud')\n",
    "    perc_amt = perc_amt.reset_index()\n",
    "    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n",
    "    amt = DataFile.groupby([Column])['TransactionAmt'].sum().reset_index()\n",
    "    perc_amt = perc_amt.fillna(0)\n",
    "    plt.subplot(212)\n",
    "    plot_2 = sns.barplot(x=Column, y='TransactionAmt', \n",
    "                       data=amt, \n",
    "                       order=list(tmp[Column].values))\n",
    "    plot_2_2 = plot_2.twinx()\n",
    "    plot_2_2 = sns.pointplot(x=Column, y='Fraud', data=perc_amt, \n",
    "                        order=list(tmp[Column].values),\n",
    "                       color='black', legend=False, )\n",
    "    plot_2_2.set_ylim(0,perc_amt['Fraud'].max()*1.1)\n",
    "    plot_2_2.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n",
    "    plot_2.set_xticklabels(plot_2.get_xticklabels(),rotation=45)\n",
    "    plot_2.set_title(f\"{Column} by Transactions Total + %of total and %Fraud Transactions\", fontsize=20)\n",
    "    plot_2.set_xlabel(f\"{Column} Category Names\", fontsize=16)\n",
    "    plot_2.set_ylabel(\"Transaction Total Amount(U$)\", fontsize=16)\n",
    "    plot_2.set_xticklabels(plot_2.get_xticklabels(),rotation=45)    \n",
    "    \n",
    "    for p in plot_2.patches:\n",
    "        height = p.get_height()\n",
    "        plot_2.text(p.get_x()+p.get_width()/2.,\n",
    "                height + 3,\n",
    "                '{:1.2f}%'.format(height/total_amt*100),\n",
    "                ha=\"center\",fontsize=12) \n",
    "        \n",
    "    plt.subplots_adjust(hspace=.4, top = 0.9)\n",
    "    plt.show()\n",
    "    \n",
    "ploting_cnt_amt(train_transaction, 'addr1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b> ADDR2 Distributions </b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploting_cnt_amt(train_transaction, 'addr2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Ploting P-Email Domain</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.loc[train_transaction['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n",
    "\n",
    "train_transaction.loc[train_transaction['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n",
    "                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n",
    "                                         'yahoo.es']), 'P_emaildomain'] = 'Yahoo Mail'\n",
    "train_transaction.loc[train_transaction['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n",
    "                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n",
    "                                         'outlook.es', 'live.com', 'live.fr',\n",
    "                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\n",
    "train_transaction.loc[train_transaction.P_emaildomain.isin(train_transaction.P_emaildomain\\\n",
    "                                         .value_counts()[train_transaction.P_emaildomain.value_counts() <= 500 ]\\\n",
    "                                         .index), 'P_emaildomain'] = \"Others\"\n",
    "train_transaction.P_emaildomain.fillna(\"NoInf\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploting_cnt_amt(train_transaction, 'R_emaildomain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Exploring C1-C14 features</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.loc[train_transaction.C1.isin(train_transaction.C1\\\n",
    "                              .value_counts()[train_transaction.C1.value_counts() <= 400 ]\\\n",
    "                              .index), 'C1'] = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploting_cnt_amt(train_transaction, 'C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction.loc[train_transaction.C2.isin(train_transaction.C2\\\n",
    "                              .value_counts()[train_transaction.C2.value_counts() <= 350 ]\\\n",
    "                              .index), 'C2'] = \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploting_cnt_amt(train_transaction, 'C2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeDelta Feature to check if frauds have some specific hour that has highest % of frauds</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/ieee-fraud-detection/discussion/100400#latest-579480\n",
    "import datetime\n",
    "\n",
    "START_DATE = '2017-12-01'\n",
    "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "train_transaction[\"Date\"] = train_transaction['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "train_transaction['_Weekdays'] = train_transaction['Date'].dt.dayofweek\n",
    "train_transaction['_Hours'] = train_transaction['Date'].dt.hour\n",
    "train_transaction['_Days'] = train_transaction['Date'].dt.day\n",
    "\n",
    "test_transaction[\"Date\"] = test_transaction['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "test_transaction['_Weekdays'] = test_transaction['Date'].dt.dayofweek\n",
    "test_transaction['_Hours'] = test_transaction['Date'].dt.hour\n",
    "test_transaction['_Days'] = test_transaction['Date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Top Days with highest Total Transaction Amount</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploting_cnt_amt(train_transaction, '_Days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Ploting WeekDays Distributions</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploting_cnt_amt(train_transaction, '_Weekdays')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Ploting Hours Distributions</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploting_cnt_amt(train_transaction, '_Hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Transactions and Total Amount per day</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "#import cufflinks\n",
    "#import cufflinks as cf\n",
    "import plotly.figure_factory as ff\n",
    "# Calling the function to transform the date column in datetime pandas object\n",
    "\n",
    "#seting some static color options\n",
    "color_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n",
    "            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n",
    "            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n",
    "\n",
    "\n",
    "dates_temp = train_transaction.groupby(train_transaction.Date.dt.date)['TransactionAmt'].count().reset_index()\n",
    "# renaming the columns to apropriate names\n",
    "\n",
    "# creating the first trace with the necessary parameters\n",
    "trace = go.Scatter(x=dates_temp['Date'], y=dates_temp.TransactionAmt,\n",
    "                    opacity = 0.8, line = dict(color = color_op[7]), name= 'Total Transactions')\n",
    "\n",
    "# Below we will get the total amount sold\n",
    "dates_temp_sum = train_transaction.groupby(train_transaction.Date.dt.date)['TransactionAmt'].sum().reset_index()\n",
    "\n",
    "# using the new dates_temp_sum we will create the second trace\n",
    "trace1 = go.Scatter(x=dates_temp_sum.Date, line = dict(color = color_op[1]), name=\"Total Amount\",\n",
    "                        y=dates_temp_sum['TransactionAmt'], opacity = 0.8, yaxis='y2')\n",
    "\n",
    "#creating the layout the will allow us to give an title and \n",
    "# give us some interesting options to handle with the outputs of graphs\n",
    "layout = dict(\n",
    "    title= \"Total Transactions and Fraud Informations by Date\",\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1, label='1m', step='month', stepmode='backward'),\n",
    "                dict(count=3, label='3m', step='month', stepmode='backward'),\n",
    "                dict(count=6, label='6m', step='month', stepmode='backward'),\n",
    "                dict(step='all')\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible = True),\n",
    "        type='date' ),\n",
    "    yaxis=dict(title='Total Transactions'),\n",
    "    yaxis2=dict(overlaying='y',\n",
    "                anchor='x', side='right',\n",
    "                zeroline=False, showgrid=False,\n",
    "                title='Total Transaction Amount')\n",
    ")\n",
    "\n",
    "# creating figure with the both traces and layout\n",
    "fig = dict(data= [trace, trace1,], layout=layout)\n",
    "\n",
    "#rendering the graphs\n",
    "iplot(fig) #it's an equivalent to plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Fraud Transactions by Date</b></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to transform the date column in datetime pandas object\n",
    "\n",
    "#seting some static color options\n",
    "color_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n",
    "            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n",
    "            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n",
    "\n",
    "tmp_amt = train_transaction.groupby([train_transaction.Date.dt.date, 'isFraud'])['TransactionAmt'].sum().reset_index()\n",
    "tmp_trans = train_transaction.groupby([train_transaction.Date.dt.date, 'isFraud'])['TransactionAmt'].count().reset_index()\n",
    "\n",
    "tmp_trans_fraud = tmp_trans[tmp_trans['isFraud'] == 1]\n",
    "tmp_amt_fraud = tmp_amt[tmp_amt['isFraud'] == 1]\n",
    "\n",
    "dates_temp = train_transaction.groupby(train_transaction.Date.dt.date)['TransactionAmt'].count().reset_index()\n",
    "# renaming the columns to apropriate names\n",
    "\n",
    "# creating the first trace with the necessary parameters\n",
    "trace = go.Scatter(x=tmp_trans_fraud['Date'], y=tmp_trans_fraud.TransactionAmt,\n",
    "                    opacity = 0.8, line = dict(color = color_op[1]), name= 'Fraud Transactions')\n",
    "\n",
    "# using the new dates_temp_sum we will create the second trace\n",
    "trace1 = go.Scatter(x=tmp_amt_fraud.Date, line = dict(color = color_op[7]), name=\"Fraud Amount\",\n",
    "                    y=tmp_amt_fraud['TransactionAmt'], opacity = 0.8, yaxis='y2')\n",
    "\n",
    "#creating the layout the will allow us to give an title and \n",
    "# give us some interesting options to handle with the outputs of graphs\n",
    "layout = dict(\n",
    "    title= \"FRAUD TRANSACTIONS - Total Transactions and Fraud Informations by Date\",\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1, label='1m', step='month', stepmode='backward'),\n",
    "                dict(count=3, label='3m', step='month', stepmode='backward'),\n",
    "                dict(count=6, label='6m', step='month', stepmode='backward'),\n",
    "                dict(step='all')\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible = True),\n",
    "        type='date' ),\n",
    "    yaxis=dict(title='Total Transactions'),\n",
    "    yaxis2=dict(overlaying='y',\n",
    "                anchor='x', side='right',\n",
    "                zeroline=False, showgrid=False,\n",
    "                title='Total Transaction Amount')\n",
    ")\n",
    "\n",
    "# creating figure with the both traces and layout\n",
    "fig = dict(data= [trace, trace1], layout=layout)\n",
    "\n",
    "#rendering the graphs\n",
    "iplot(fig) #it's an equivalent to plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "LOCAL_TEST = False\n",
    "TARGET = 'isFraud'\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load Data')\n",
    "train_df = pd.read_pickle('../input/ieee-data-minification/train_transaction.pkl')\n",
    "\n",
    "if LOCAL_TEST:\n",
    "    \n",
    "    train_df['DT_M'] = train_df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "    train_df['DT_M'] = (train_df['DT_M'].dt.year-2017)*12 + train_df['DT_M'].dt.month \n",
    "    test_df = train_df[train_df['DT_M']==train_df['DT_M'].max()].reset_index(drop=True)\n",
    "    train_df = train_df[train_df['DT_M']<(train_df['DT_M'].max()-1)].reset_index(drop=True)\n",
    "    \n",
    "    train_identity = pd.read_pickle('../input/ieee-data-minification/train_identity.pkl')\n",
    "    test_identity  = train_identity[train_identity['TransactionID'].isin(\n",
    "                                    test_df['TransactionID'])].reset_index(drop=True)\n",
    "    train_identity = train_identity[train_identity['TransactionID'].isin(\n",
    "                                    train_df['TransactionID'])].reset_index(drop=True)\n",
    "    del train_df['DT_M'], test_df['DT_M']\n",
    "    \n",
    "else:\n",
    "    test_df = pd.read_pickle('../input/ieee-data-minification/test_transaction.pkl')\n",
    "    train_identity = pd.read_pickle('../input/ieee-data-minification/train_identity.pkl')\n",
    "    test_identity = pd.read_pickle('../input/ieee-data-minification/test_identity.pkl')\n",
    "    \n",
    "base_columns = list(train_df) + list(train_identity)\n",
    "print('Shape control:', train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = ['card1']\n",
    "\n",
    "for col in i_cols: \n",
    "    valid_card = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    valid_card = valid_card[col].value_counts()\n",
    "    valid_card = valid_card[valid_card>2]\n",
    "    valid_card = list(valid_card.index)\n",
    "\n",
    "    train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = ['card1','card2','card3','card5',\n",
    "          'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "          'D1','D2','D3','D4','D5','D6','D7','D8','D9',\n",
    "          'addr1','addr2',\n",
    "          'dist1','dist2'\n",
    "         ]\n",
    "\n",
    "for col in i_cols:\n",
    "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()   \n",
    "    train_df[col+'_fq_enc'] = train_df[col].map(fq_encode)\n",
    "    test_df[col+'_fq_enc']  = test_df[col].map(fq_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['ProductCD','M4']:\n",
    "    temp_dict = train_df.groupby([col])[TARGET].agg(['mean']).reset_index().rename(\n",
    "                                                        columns={'mean': col+'_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col+'_target_mean'].to_dict()\n",
    "\n",
    "    train_df[col+'_target_mean'] = train_df[col].map(temp_dict)\n",
    "    test_df[col+'_target_mean']  = test_df[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cols = ['M1','M2','M3','M5','M6','M7','M8','M9']\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['M_sum'] = df[i_cols].sum(axis=1).astype(np.int8)\n",
    "    df['M_na'] = df[i_cols].isna().sum(axis=1).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['uid'] = train_df['card1'].astype(str)+'_'+train_df['card2'].astype(str)\n",
    "test_df['uid'] = test_df['card1'].astype(str)+'_'+test_df['card2'].astype(str)\n",
    "\n",
    "train_df['uid2'] = train_df['uid'].astype(str)+'_'+train_df['card3'].astype(str)+'_'+train_df['card4'].astype(str)\n",
    "test_df['uid2'] = test_df['uid'].astype(str)+'_'+test_df['card3'].astype(str)+'_'+test_df['card4'].astype(str)\n",
    "\n",
    "train_df['uid3'] = train_df['uid2'].astype(str)+'_'+train_df['addr1'].astype(str)+'_'+train_df['addr2'].astype(str)\n",
    "test_df['uid3'] = test_df['uid2'].astype(str)+'_'+test_df['addr1'].astype(str)+'_'+test_df['addr2'].astype(str)\n",
    "\n",
    "train_df['TransactionAmt_check'] = np.where(train_df['TransactionAmt'].isin(test_df['TransactionAmt']), 1, 0)\n",
    "test_df['TransactionAmt_check']  = np.where(test_df['TransactionAmt'].isin(train_df['TransactionAmt']), 1, 0)\n",
    "\n",
    "i_cols = ['card1','card2','card3','card5','uid','uid2','uid3']\n",
    "\n",
    "for col in i_cols:\n",
    "    for agg_type in ['mean','std']:\n",
    "        new_col_name = col+'_TransactionAmt_'+agg_type\n",
    "        temp_df = pd.concat([train_df[[col, 'TransactionAmt']], test_df[[col,'TransactionAmt']]])\n",
    "        #temp_df['TransactionAmt'] = temp_df['TransactionAmt'].astype(int)\n",
    "        temp_df = temp_df.groupby([col])['TransactionAmt'].agg([agg_type]).reset_index().rename(\n",
    "                                                columns={agg_type: new_col_name})\n",
    "        \n",
    "        temp_df.index = list(temp_df[col])\n",
    "        temp_df = temp_df[new_col_name].to_dict()   \n",
    "    \n",
    "        train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "        test_df[new_col_name]  = test_df[col].map(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(train_df):\n",
    "    if train_df[col].dtype=='O':\n",
    "        print(col)\n",
    "        train_df[col] = train_df[col].fillna('unseen_before_label')\n",
    "        test_df[col]  = test_df[col].fillna('unseen_before_label')\n",
    "        \n",
    "        train_df[col] = train_df[col].astype(str)\n",
    "        test_df[col] = test_df[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train_df[col])+list(test_df[col]))\n",
    "        train_df[col] = le.transform(train_df[col])\n",
    "        test_df[col]  = le.transform(test_df[col])\n",
    "        \n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "        test_df[col] = test_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cols = [\n",
    "    'TransactionID','TransactionDT', # These columns are pure noise right now\n",
    "    TARGET,                          # Not target in features))\n",
    "    'uid','uid2','uid3',             # Our new client uID -> very noisy data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_columns = list(train_df)\n",
    "for col in rm_cols:\n",
    "    if col in features_columns:\n",
    "        features_columns.remove(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                'objective':'binary',\n",
    "                'boosting_type':'gbdt',\n",
    "                'metric':'auc',\n",
    "                'n_jobs':-1,\n",
    "                'learning_rate':0.064,\n",
    "                'num_leaves': 2**8,\n",
    "                'max_depth':-1,\n",
    "                'tree_learner':'serial',\n",
    "                'colsample_bytree': 0.85,\n",
    "                'subsample_freq':1,\n",
    "                'subsample':0.85,\n",
    "                'n_estimators':2**9,\n",
    "                'max_bin':255,\n",
    "                'verbose':-1,\n",
    "                'seed': SEED,\n",
    "                'early_stopping_rounds':100,\n",
    "                'reg_alpha':0.3,\n",
    "                'reg_lamdba':0.243\n",
    "            } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model\n",
    "import lightgbm as lgb\n",
    "\n",
    "def make_predictions(tr_df, tt_df, features_columns, target, lgb_params, NFOLDS=2):\n",
    "    folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    X,y = tr_df[features_columns], tr_df[target]    \n",
    "    P,P_y = tt_df[features_columns], tt_df[target]  \n",
    "\n",
    "    tt_df = tt_df[['TransactionID',target]]    \n",
    "    predictions = np.zeros(len(tt_df))\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        print('Fold:',fold_)\n",
    "        tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n",
    "        vl_x, vl_y = X.iloc[val_idx,:], y[val_idx]\n",
    "            \n",
    "        print(len(tr_x),len(vl_x))\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "\n",
    "        if LOCAL_TEST:\n",
    "            vl_data = lgb.Dataset(P, label=P_y) \n",
    "        else:\n",
    "            vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "\n",
    "        estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_data,\n",
    "            valid_sets = [tr_data, vl_data],\n",
    "            verbose_eval = 200,\n",
    "        )   \n",
    "        \n",
    "        pp_p = estimator.predict(P)\n",
    "        predictions += pp_p/NFOLDS\n",
    "\n",
    "        if LOCAL_TEST:\n",
    "            feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\n",
    "            print(feature_imp)\n",
    "        \n",
    "        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n",
    "        gc.collect()\n",
    "        \n",
    "    tt_df['prediction'] = predictions\n",
    "    \n",
    "    return tt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOCAL_TEST:\n",
    "    test_predictions = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params)\n",
    "    print(metrics.roc_auc_score(test_predictions[TARGET], test_predictions['prediction']))\n",
    "else:\n",
    "    lgb_params['learning_rate'] = 0.005\n",
    "    lgb_params['n_estimators'] = 2000\n",
    "    lgb_params['early_stopping_rounds'] = 100    \n",
    "    test_predictions = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params, NFOLDS=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOCAL_TEST:\n",
    "    test_predictions['isFraud'] = test_predictions['prediction']\n",
    "    test_predictions[['TransactionID','isFraud']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
